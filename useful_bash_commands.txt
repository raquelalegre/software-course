USEFUL BASH COMMANDS
--------------------

A Bash script is nothing more than a sequence of Unix commands. You can normally just get the contents of a basch script, 
and copy-paste them directly in the shell.
Putting all those commands together and saving them in a script file is just a tidy way of doing things. You can keep it 
for later, reuse it, share it, etc.
To be able to make a nice script, you will first need to know a few commands. Here are some:


Move around your file system
----------------------------

A path is the unique location where a file or folder is. For example: /home/your_username is the path to your desktop.

To go to a path you need the "cd" command, which stands for "change directory". For example:
cd /home
cd /home/your_username
cd ../other_username/software-course/exercise1/resources
cd ..
cd .
cd
cd ~/
cd -

Paths can be absolute or relative. 

An absolute path is the location of a file or folder starting always in the root directory: "/". For example:
/home/your_username/software-course

A relative path is the location of a file or folder from where you are now, your current working path. For example, if you are in:
/home/your_username/software-course/exercise1

and want to go to the exercise2 folder, you could do:
cd ../exercise2

which is equivalent to going to this absolute path:
cd /home/your_username/software-course/exercise2

"../" and ".." mean parent directory. So in this last example, you go to parent directory, and then exercise2. 

"./" and "." mean current directory. You wouldn't normally want to cd there, because you are already there (duh), but you 
will want to use it for commands other than "cd".

You could also do:
cd -

This means "take me back to the directory I was just before". This is the equivalent to the backwards arrow in a web browser. 
It's really useful when you didn't remember where you were before or it's a really long path to type and you are feeling 
rather lazy. Cons: it only goes back one step, it doesn't have a big memory. This means if you type "cd -" twice, 
you will end up in the same place where you started.

Another useful command is "pwd". It stands for "print working directory". It will return the absolute path to where you are 
and it's a very handy command when you are feeling lost. 

"~/" represents your home directory. Notice the two following commands do the same thing:
cd
cd ~/

You can check how the result is the same by executing "pwd" after each command.

Some locations of folders and files you'll know by heart, but it's likely you won't know your entire file system, so you'll 
need commands that show you what options you have.
The most used command for this purpose is "ls".
If you type it in you current folder, it'll list all the files and folders in it.
You can also do "ls some_path" and see the list of folders and files in a different place. For example:
ls /bin

Unix commands accept arguments you can pass. "ls" is no exception. To know all options you have with a command, you can use "man":
man ls
(Exit this help by typing "q")

Try now:
ls -ltrah ~/

Check in the man output what each modifier is for and try others you like.

Another useful command to know is "tree". Let's go to our home directory and see what's in there:
cd ~/
tree

Note that the command tree might not have been installed yet in you OS and you'll need to do this:
sudo apt-get install tree

This is a rather advanced command for installing a new program in your system. You might need an admin password and help 
from someone else in the course, but the "tree" command is worth the effort.


Edit your filesystem
--------------------

Have a quick look with man to the following useful commands and their arguments:
mkdir
rmdir
rm 
cp
mv

Try to do the following in a test folder:
1.  Create a new folder named "test"
2.  Go inside the folder
3.  Create several new folders named "subfolder1", "subfolder2" and "subfolder3"
4.  Go inside "subfolder1"
5.  Create an empty file: touch "fileA"
6.  Copy "fileA" to "subfolder2"
7.  Rename "fileA" to "fileB"
8.  Move "fileB" to "subfolder3"
9.  Remove "fileA"
10. Check the contents of all folders and remove the one/s empty
11. Try to remove the whole "test" folder with the "rmdir" command. What happened? How would you remove it? (Hint: try both "man 
rm" and "man rmdir")
12. Advanced: make this process into a script and run it.

Solution:
1.  mkdir test
2.  cd test
3.  mkdir subfolder1 subfolder2 subfolder3
4.  cd subfolder1
5.  touch fileA.test
6.  cp fileA.test ../subfolder2
7.  cd ../subfolder2
    mv fileA.test fileB.test
8.  mv fileB.test ../subfolder3
9.  rm ../subfolder1/fileA.test 
10. cd ..
    tree
    rmdir subfolder1 subfolder2 
11. cd ..
    rmdir test - won't work because it's not empty
    rm -rf test
12. touch script.sh
    kate script.sh &
    Copy and paste all the previous step
    Save and close
    Give execution permissions: chmod a+x script.sh
    Run script: ./script.sh




Text files
----------

There are serveral useful commands for working with text files. 

"touch" creates an empty file. For example:
touch my_file.txt

Do "ls" and check this file has been correctly created.

Open it for editting with a tool like kate:
kate "my_file.txt" &

Insert some random text:
Hello, I'm a text file. 
I contain really important data.

Let's do this again:

touch another_file.txt

kate another_file.txt &

Write some more random text:
Hello, I'm another text file.
I contain really unimportant data.

Save and close the files. 

"cat" prints out the contents of a text file. Try:
cat my_file.txt

or:
cat *.txt

This last one will print out the contents of all files with ".txt" extension.

"grep" is a very powerful command for looking for specific content in a file. Try:
grep "unimportant data" *

It will come up with the relative path to the files in your working directory that contain the text "unimportant data". 
In this case it's only one: another_file.txt. 

Try now:
grep "important data" *

How is the output different than the previous case?

Have a look at what these other commands useful for working with text files:
head
tail
more
less
sort
wc
awk
sed
cut



Standard Output and Standard Error
--------------------------------------------------

The shell uses what we call "streams" to manage execution outputs from commands or programs.
To refer to these, we use numbers:
1: Standard Output, or stdout. For example, when you execute "ls" and it comes up with a list of files and folders, 
that list is the Standard Output of the command.
2: Standard Error (special kind of output), or stderr. These are outputs related to errors that occurr when executing a 
command. For example, if you execute "ls /unexistent folder", the output message stating there is not such a folder and 
thus ls can't be successfully executed, go to stderr.


Redirecting Standard Output and Standard Error to log files
-----------------------------------------------------------

Normally both stdout and stderr are displayed in the shell, but it's handy to have a way to refer to them separately and have 
the possibility to redirect them somewhere else. 

The most commom Bash notation for redirection of output is ">". 

For example, try:
ls ./

See the output? Now try to redirect it to a file ./ls.stdout:
ls ./ > ./ls.out

You have not seen any outputs in the prompt this time, they should all be in the file ./ls.stdout. Check its contents with 
the "cat" command:
cat ./ls.out

See? Now let's try to cause an error in the ls command by giving it an unexistent folder:
ls ./made_up_folder

You should get an error message saying that folder doesn't exist. Try to redirect the output like before:
ls ./made_up_folder > ./ls.err

The behaviour this time is different, because when Bash sees ">" without spefying what stream we are talking about, it defaults 
to redirecting only stdout and doesn't include the error output. To speficy which stream/s you want to redirect, use the ID 
numbers they have (1 for stout and 2 for stderr). For example:
ls ./made_up_folder 2>./ls.err

Check the contents of the file now:
cat ./ls.err


Let's try something a bit more elaborate: loop recursively through all files and folders in our current directory 
(software-course) and print them out with the "cat" command. "cat" will throw an error when we pass a folder instead of a file. 
Let's build the command. First, loop through all files and folders in current directory with the find command, which simplified syntax is:
find [FOLDER] -name [REGEX] 

In our case, current folder is "." and the REGEX is "*" meaning all files and folders under any name:
find . -name "*"

Now, for each of the outputs, run the "cat" command on them. For this we use pipes (next section), represented by "|". For example:
find ~/ -name "" | xargs cat 

This command will go through all the files in ~/ and try to cat them. This will work for all text files, but not for other 
things like binaries or folders, thus an error message would be displayed.
Let's save the contents of each file in an stdout.log and the error messages in stderr.log
find ~/ -name "" | xargs cat  1>stdout.log 2>stderr.log

There is a very good cheat sheet about redirection here: http://www.catonmat.net/download/bash-redirections-cheat-sheet.pdf


Pipes
-----

The "|" symbol is used for "piping" unix commands.
 
When bash examines the command line, it finds the vertical bar character | that separates the two commands. For example:
ls | grep "a"

Bash and other shells run both commands, connecting the output of the first to the input of the second. 
The ls program produces a list of files in the current directory, while the grep program reads the output of ls and prints 
only those lines containing the letter "a".

The "find" and the "grep" commands can be very powerful together. You might want to have a look in all directories for a text 
file that contains a specific word. For example
find . -name "*.txt" | xargs grep "some sentence"

"find" will produce a list of results, and for each of them (xargs), the grep command will be executed looking at the content 
of the file for "some sentence".

You might want to count the number of lines of each text file in your current folder and subfolders, and view that associated 
to each file:
find . -name "*.txt" | xargs wc -l

Or you might want to sort alphabetically the contents of a file:
cat file.txt | sort 


Variables
---------




Special Variables
-----------------
We've already discuss $?, but there are many other special variables Bash uses to manage it's execution environment.
For example:
$#
$!
$0
$1, $2, $3...
$PATH








History and autocompletion
--------------------------

You can have a look at the latest commands you've used by just typing:
history

or just:
h

If you want to see everytime you have use the command "mkdir", you can do:
history | grep mkdir

If you press Ctrl and R, you can start typing a command you remember, and keep pressing Ctrl+R which will go backwards in your 
history showing all commands matching your input. It takes a while to get use to it, but you can't live without it afterwards.

You can re-run the latest command executed by doing this:
!!

It's a bit dangerous, you have to be really sure that won't produce any data loss, etc.

You can also re-run the latest command starting with letter c by typing:
!c

If you start writing a command or a path and then press the tab key, the shell will try to complete or give you suggestions of 
commands of paths starting with what you have written.

Up and Down arow keys will also help navigate the command history buffer.













